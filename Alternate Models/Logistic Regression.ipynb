{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[Comparison, with, alkaline, phosphatases, and...</td>\n",
       "      <td>[O, O, B, I, O, B, I, I, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[Pharmacologic, aspects, of, neonatal, hyperbi...</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[When, CSF, [, HCO3, -], is, shown, as, a, fun...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Flurazepam, thus, appears, to, be, an, effect...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[Beta, blocking, agents, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Expression, of, SREBP, -, 1a, stimulated, StA...</td>\n",
       "      <td>[O, O, B, I, I, O, B, I, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Because, the, high, -, density, lipoprotein, ...</td>\n",
       "      <td>[O, O, B, I, I, I, I, O, B, I, I, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[IFN, -, stimulated, gene, factor, -, 3, and, ...</td>\n",
       "      <td>[B, I, I, I, I, I, I, O, B, I, O, O, O, O, B, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[We, have, therefore, studied, the, molecular,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, O, O, B, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[The, epitope, -, protected, lysine, (, K, ), ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B, I, I, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13795 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   index  \\\n",
       "0                            [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "1                                     [1, 2, 3, 4, 5, 6]   \n",
       "2      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4                                           [1, 2, 3, 4]   \n",
       "...                                                  ...   \n",
       "13790  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13791  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13792  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13793  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13794  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                         tokenized_sents  \\\n",
       "0      [Comparison, with, alkaline, phosphatases, and...   \n",
       "1      [Pharmacologic, aspects, of, neonatal, hyperbi...   \n",
       "2      [When, CSF, [, HCO3, -], is, shown, as, a, fun...   \n",
       "3      [Flurazepam, thus, appears, to, be, an, effect...   \n",
       "4                            [Beta, blocking, agents, .]   \n",
       "...                                                  ...   \n",
       "13790  [Expression, of, SREBP, -, 1a, stimulated, StA...   \n",
       "13791  [Because, the, high, -, density, lipoprotein, ...   \n",
       "13792  [IFN, -, stimulated, gene, factor, -, 3, and, ...   \n",
       "13793  [We, have, therefore, studied, the, molecular,...   \n",
       "13794  [The, epitope, -, protected, lysine, (, K, ), ...   \n",
       "\n",
       "                                                   label  \n",
       "0                            [O, O, B, I, O, B, I, I, O]  \n",
       "1                                     [O, O, O, O, O, O]  \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4                                           [O, O, O, O]  \n",
       "...                                                  ...  \n",
       "13790  [O, O, B, I, I, O, B, I, O, O, O, O, O, O, O, ...  \n",
       "13791  [O, O, B, I, I, I, I, O, B, I, I, O, O, O, O, ...  \n",
       "13792  [B, I, I, I, I, I, I, O, B, I, O, O, O, O, B, ...  \n",
       "13793  [O, O, O, O, O, O, O, O, B, I, I, O, O, B, O, ...  \n",
       "13794  [O, O, O, O, O, O, O, O, O, O, O, O, B, I, I, ...  \n",
       "\n",
       "[13795 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = open('S21-gene-train.txt').readlines()\n",
    "\n",
    "entries = {'index':[],\n",
    "            'tokenized_sents':[],\n",
    "            'label':[]}\n",
    "\n",
    "current_index = []\n",
    "current_sentence = []\n",
    "current_label = []\n",
    "\n",
    "\n",
    "\n",
    "for i, line in enumerate(raw_text) : \n",
    "\n",
    "        if line==\"\\n\":\n",
    "            entries['index'].append(current_index)\n",
    "            entries['tokenized_sents'].append(current_sentence)\n",
    "            entries['label'].append(current_label)\n",
    "            \n",
    "            current_index = []\n",
    "            current_sentence = []\n",
    "            current_label = []\n",
    "        \n",
    "        else : \n",
    "\n",
    "            index, word, label = line.split(\"\\t\")\n",
    "\n",
    "            current_index.append(index)\n",
    "            current_sentence.append(word)\n",
    "            current_label.append(label.strip())\n",
    "\n",
    "df = pd.DataFrame(entries)\n",
    "\n",
    "# df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['sentence']), axis=1)\n",
    "# df = df.drop(columns = ['sentence'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] ['By', 'contrast', ',', 'secretory', 'HI', 'antibodies', 'were', 'not', 'demonstrated', 'at', 'the', 'onset', 'of', 'illness', 'in', 'any', 'of', 'the', 'patients', ',', 'but', 'their', 'formation', 'started', 'early', 'and', 'the', 'antibodies', 'reached', 'maximal', 'levels', 'about', '10', 'days', 'after', 'onset', 'of', 'illness', '.']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'][12], df['tokenized_sents'][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_words = []\n",
    "i_words = []\n",
    "o_words = []\n",
    "\n",
    "all_words = []\n",
    "all_labels = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    for k, ele in enumerate(row['label']):\n",
    "        all_words.append(row['tokenized_sents'][k])\n",
    "        all_labels.append(ele)\n",
    "        if ele == 'B':\n",
    "            b_words.append(row['tokenized_sents'][k])\n",
    "        elif ele == 'I':\n",
    "            i_words.append(row['tokenized_sents'][k])\n",
    "        elif ele == 'O':\n",
    "            o_words.append(row['tokenized_sents'][k])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " B tagged words :  ['alkaline', '5', 'carbonic', 'HMG', 'Serum', 'secretory', 'lipase', 'HLA', 'SGPT', 'SGOT'] \n",
      "\n",
      " I tagged words :  ['phosphatases', '-', 'nucleotidase', 'anhydrase', 'gamma', 'glutamyltransferase', 'HI', 'antibodies', '-', 'B5'] \n",
      "\n",
      " O tagged words :  ['Comparison', 'with', 'and', '.', 'Pharmacologic', 'aspects', 'of', 'neonatal', 'hyperbilirubinemia', '.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparison</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alkaline</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phosphatases</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386148</th>\n",
       "      <td>found</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386149</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386150</th>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386151</th>\n",
       "      <td>K713</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386152</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               words labels\n",
       "0         Comparison      O\n",
       "1               with      O\n",
       "2           alkaline      B\n",
       "3       phosphatases      I\n",
       "4                and      O\n",
       "...              ...    ...\n",
       "386148         found      O\n",
       "386149            to      O\n",
       "386150            be      O\n",
       "386151          K713      O\n",
       "386152             .      O\n",
       "\n",
       "[386153 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comp_print(b, i, o):\n",
    "    print(\"\\n B tagged words : \", b, \"\\n\\n\", \"I tagged words : \", i, \"\\n\\n\", \"O tagged words : \", o)\n",
    "    \n",
    "comp_print(b_words[0:10], i_words[0:10], o_words[0:10])\n",
    "tag_df = pd.DataFrame({'words': all_words, 'labels': all_labels})\n",
    "tag_df.to_csv('BI.csv')\n",
    "tag_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-', 4390), ('1', 872), ('gene', 863), ('protein', 710), ('kinase', 422), ('2', 368), ('factor', 343), ('promoter', 309), ('binding', 275), ('alpha', 272), ('receptor', 269), ('(', 242), ('proteins', 233), ('/', 227), (')', 214), ('beta', 210), ('3', 203), ('genes', 188), ('.', 165), ('I', 161)] \n",
      "\n",
      " [('human', 265), ('c', 221), ('beta', 111), ('NF', 110), ('IL', 108), ('alpha', 98), ('AP', 98), ('protein', 89), ('C', 83), ('Sp1', 80), ('insulin', 78), ('serum', 74), ('cyclin', 71), ('RNA', 66), ('mouse', 63), ('rat', 63), ('anti', 62), ('Ras', 62), ('p53', 61), ('CAT', 50)]\n",
      "['-', '1', 'gene', 'protein', 'kinase', '2', 'factor', 'promoter', 'binding', 'alpha', 'receptor', '(', 'proteins', '/', ')', 'beta', '3', 'genes', '.', 'I']\n",
      "['human', 'c', 'beta', 'NF', 'IL', 'alpha', 'AP', 'protein', 'C', 'Sp1', 'insulin', 'serum', 'cyclin', 'RNA', 'mouse', 'rat', 'anti', 'Ras', 'p53', 'CAT']\n",
      "['the', '.', 'of', ',', 'and', '-', 'in', 'a', 'to', '(', 'with', ')', 'that', 'The', 'was', 'for', 'by', 'is', 'were', '/']\n"
     ]
    }
   ],
   "source": [
    "k = Counter(i_words).most_common(20)\n",
    "j = Counter(b_words).most_common(20)\n",
    "l = Counter(o_words).most_common(20)\n",
    "\n",
    "i_most_common = set([ele[0] for ele in Counter(i_words).most_common(20)])\n",
    "b_most_common = set([ele[0] for ele in Counter(b_words).most_common(20)])\n",
    "o_most_common = set([ele[0] for ele in Counter(o_words).most_common(20)])\n",
    "\n",
    "\n",
    "# Pass the required word set as the first argument\n",
    "# This function gives the unique characters in each class\n",
    "def find_diff(i, ii, iii):\n",
    "    diff = i.difference(ii)\n",
    "    diff = diff.difference(iii)\n",
    "    return diff\n",
    "\n",
    "print(k, \"\\n\\n\" , j)\n",
    "\n",
    "print([ele[0] for ele in k])\n",
    "print([ele[0] for ele in j])\n",
    "print([ele[0] for ele in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b-word endings:\n",
      "[('ase', 299), ('man', 289), ('lin', 266), ('c', 221), ('ine', 219)]\n",
      "[('in', 1035), ('se', 391), ('an', 371), ('ne', 308), ('c', 221)]\n",
      "\n",
      "i-word endings:\n",
      "[('-', 4390), ('ase', 1185), ('ene', 903), ('1', 872), ('ein', 781)]\n",
      "[('-', 4390), ('in', 1429), ('se', 1242), ('ne', 1169), ('1', 872)]\n",
      "\n",
      "o-word endings:\n",
      "[('the', 15494), ('.', 15344), ('of', 14672), (',', 12110), ('ion', 10960)]\n",
      "[('he', 18069), ('ed', 15371), ('.', 15344), ('of', 14677), ('on', 13123)]\n"
     ]
    }
   ],
   "source": [
    "def find_word_endings(word_list):\n",
    "    word_endings = []\n",
    "    word_endings2 = []\n",
    "\n",
    "    for ele in word_list:\n",
    "        word_endings.append(ele[-3:])\n",
    "        \n",
    "    for ele in word_list:\n",
    "        word_endings2.append(ele[-2:])\n",
    "        \n",
    "    print(Counter(word_endings).most_common(5))\n",
    "    print(Counter(word_endings2).most_common(5))\n",
    "\n",
    "print('b-word endings:')\n",
    "find_word_endings(b_words)\n",
    "print()\n",
    "print('i-word endings:')\n",
    "find_word_endings(i_words)\n",
    "print()\n",
    "print('o-word endings:')\n",
    "find_word_endings(o_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for data exploration - comparitive evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_explore:\n",
    "    \n",
    "    def __init__(self, word_list):\n",
    "        self.word_list = word_list\n",
    "\n",
    "    # Check if all words are upper case\n",
    "\n",
    "    def check_all_upper(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            temp_l.append(bool(re.match(r'[A-Z]+$', ele)))\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if word ends with 'ase'\n",
    "    def check_ase(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if 'ase' in ele:\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "    \n",
    "    # Check if word ends with 'ene' endings\n",
    "    def check_ene(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if 'ene' in ele[-3:]:\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "    \n",
    "    # Check if word ends with 'ein'/'tor' endings\n",
    "    def check_ein(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if (('ein' or 'tor') in ele[-3:]):\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if word contains a hyphen\n",
    "    def check_dash(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if '-' in ele:\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "                \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if all upper case letters + numbers present in word\n",
    "    def check_all_upper_number(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            without_num = ''.join(i for i in ele if not i.isdigit())\n",
    "            temp_l.append(bool(re.match(r'[A-Z]+$', without_num)) and (bool(re.search(r'\\d', ele))))\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if number is present in word alongside other letters\n",
    "    def check_num_with_chars(self, ret_list = False):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            without_num = ''.join(i for i in ele if not i.isdigit())\n",
    "            temp_l.append(bool(re.match(r'[A-Za-z]+$', without_num)) and (bool(re.search(r'\\d', ele))))\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        # return number and ratio\n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if the word does not match with any stopword\n",
    "    def check_stopword_absence(self, ret_list = False):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if ele not in stop_words:\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check if the word does not match with any stopword and contains lower_case characters\n",
    "    def check_stopword_absence_lcase(self, ret_list = False):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if ((ele not in stop_words) and (bool(re.match(r'[a-z]+$', ele)))):\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    # Check for common terms\n",
    "    def check_comm_i_terms(self, ret_list = False):\n",
    "        # i_list = [ele[0] for ele in Counter(i_words).most_common(10)]\n",
    "        # i_list = ['-', 'gene', 'protein','kinase','factor','promoter','(', 'binding']\n",
    "        \n",
    "        i_list = find_diff(i_most_common, b_most_common, o_most_common)\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if (ele in i_list):\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    def check_comm_b_terms(self, ret_list = False):\n",
    "        # i_list = [ele[0] for ele in Counter(i_words).most_common(10)]\n",
    "        # i_list = ['-', 'gene', 'protein','kinase','factor','promoter','(', 'binding']\n",
    "        \n",
    "        i_list = find_diff(b_most_common, i_most_common, o_most_common)\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if (ele in i_list):\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    def check_comm_o_terms(self, ret_list = False):\n",
    "        # i_list = [ele[0] for ele in Counter(i_words).most_common(10)]\n",
    "        # i_list = ['-', 'gene', 'protein','kinase','factor','promoter','(', 'binding']\n",
    "        \n",
    "        i_list = find_diff(o_most_common, b_most_common, i_most_common)\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            if (ele in i_list):\n",
    "                temp_l.append(True)\n",
    "            else:\n",
    "                temp_l.append(False)\n",
    "        \n",
    "        if ret_list:\n",
    "            return temp_l\n",
    "        \n",
    "        return (Counter(temp_l), Counter(temp_l)[True]/len(temp_l))\n",
    "\n",
    "    def word_len(self):\n",
    "        temp_l = []\n",
    "        for ele in self.word_list:\n",
    "            temp_l.append(len(ele))\n",
    "        \n",
    "        return temp_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing out feature results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper case characters:\n",
      "\n",
      " B tagged words :  (Counter({False: 12451, True: 4181}), 0.2513828763828764) \n",
      "\n",
      " I tagged words :  (Counter({False: 22225, True: 2197}), 0.08995987224633527) \n",
      "\n",
      " O tagged words :  (Counter({False: 335124, True: 9975}), 0.028904749072005423)\n",
      "--------------------------------------------------------------------------------\n",
      "'ase' endings characters:\n",
      "\n",
      " B tagged words :  (Counter({False: 16308, True: 324}), 0.01948051948051948) \n",
      "\n",
      " I tagged words :  (Counter({False: 23085, True: 1337}), 0.05474572107116534) \n",
      "\n",
      " O tagged words :  (Counter({False: 342955, True: 2144}), 0.006212709975977908)\n",
      "--------------------------------------------------------------------------------\n",
      "Check for hyphens\n",
      "\n",
      " B tagged words :  (Counter({False: 16630, True: 2}), 0.00012025012025012025) \n",
      "\n",
      " I tagged words :  (Counter({False: 19955, True: 4467}), 0.18290885267381868) \n",
      "\n",
      " O tagged words :  (Counter({False: 335330, True: 9769}), 0.028307818915731427)\n",
      "--------------------------------------------------------------------------------\n",
      "Stopword absence + lowercase\n",
      "\n",
      " B tagged words :  (Counter({False: 11750, True: 4882}), 0.29353054353054353) \n",
      "\n",
      " I tagged words :  (Counter({False: 12386, True: 12036}), 0.49283432970272706) \n",
      "\n",
      " O tagged words :  (Counter({True: 244404, False: 100695}), 0.7082141646310189)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check if all characters are upper case\n",
    "print(\"Upper case characters:\")\n",
    "comp_print(data_explore(b_words).check_all_upper(), data_explore(i_words).check_all_upper(), data_explore(o_words).check_all_upper())\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "# Check if characters ase\n",
    "print(\"\\'ase\\' endings characters:\")\n",
    "comp_print(data_explore(b_words).check_ase(), data_explore(i_words).check_ase(), data_explore(o_words).check_ase())\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Check for hyphens\n",
    "print(\"Check for hyphens\")\n",
    "comp_print(data_explore(b_words).check_dash(), data_explore(i_words).check_dash(), data_explore(o_words).check_dash())\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "# Check stop-word absence\n",
    "print(\"Stopword absence + lowercase\")\n",
    "comp_print(data_explore(b_words).check_stopword_absence_lcase(), data_explore(i_words).check_stopword_absence_lcase(), data_explore(o_words).check_stopword_absence())\n",
    "print(\"--------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run logistic regression on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alkaline</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>phosphatases</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>found</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386150</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>K713</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386153 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9         words labels\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    Comparison      O\n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0          with      O\n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      alkaline      B\n",
       "3       0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  phosphatases      I\n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0           and      O\n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...           ...    ...\n",
       "386148  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0         found      O\n",
       "386149  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0            to      O\n",
       "386150  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0            be      O\n",
       "386151  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0          K713      O\n",
       "386152  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0             .      O\n",
       "\n",
       "[386153 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def create_feature_df(all_words):\n",
    "\n",
    "    fin_df = pd.DataFrame()\n",
    "\n",
    "    words = data_explore(all_words)\n",
    "\n",
    "    fin_df['all_upper'] = words.check_all_upper(ret_list = True)\n",
    "    fin_df['ase'] = words.check_ase(ret_list = True)\n",
    "    fin_df['all_upper_num'] = words.check_all_upper_number(ret_list = True)\n",
    "    fin_df['hyphen'] = words.check_dash(ret_list = True)\n",
    "    fin_df['num_with_chars'] = words.check_num_with_chars(ret_list = True)\n",
    "    fin_df['ene'] = words.check_ene(ret_list = True)\n",
    "    fin_df['ein'] = words.check_ein(ret_list = True)\n",
    "    # fin_df['stopword_absence'] = words.check_stopword_absence(ret_list = True)\n",
    "    # fin_df['stopword_absence_lcase'] = words.check_stopword_absence_lcase(ret_list = True)\n",
    "    fin_df['comm_i_terms'] = words.check_comm_i_terms(ret_list = True)\n",
    "    fin_df['comm_o_terms'] = words.check_comm_o_terms(ret_list = True)\n",
    "    fin_df['comm_b_terms'] = words.check_comm_b_terms(ret_list = True)\n",
    "    # fin_df['word_len'] = words.word_len()\n",
    "\n",
    "    \n",
    "    # Convert to int\n",
    "    fin_df = fin_df*1\n",
    "    x = fin_df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    fin_df = pd.DataFrame(x_scaled)\n",
    "    # fin_df=(fin_df-fin_df.mean())/fin_df.std()\n",
    "    \n",
    "    \n",
    "    return fin_df \n",
    "\n",
    "fin_df = create_feature_df(all_words)\n",
    "fin_df['words'] = all_words\n",
    "fin_df['labels'] = all_labels\n",
    "fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 310608, 'I': 21957, 'B': 14972})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cop_df = fin_df.copy()\n",
    "\n",
    "# print(Counter(cop_df['labels']))\n",
    "# cop_df = cop_df.groupby('labels').apply(lambda x: x.sample(16632))\n",
    "\n",
    "\n",
    "# print(Counter(cop_df['labels']))\n",
    "\n",
    "# temp_df = cop_df.copy()\n",
    "# temp_df.drop(columns = ['words'], inplace = True)\n",
    "\n",
    "# print(temp_df.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cop_df.loc[:, cop_df.columns != 'labels'], cop_df.loc[:, cop_df.columns == 'labels'], test_size=0.1, random_state=10)\n",
    "print(Counter(y_train['labels'])) \n",
    "\n",
    "# X, y = fin_df.loc[:, fin_df.columns != 'labels'], fin_df.loc[:, fin_df.columns == 'labels']\n",
    "clf = LogisticRegression(random_state=0, class_weight='balanced').fit(X_train.drop(columns = ['words']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier : \n",
      "0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of classifier : \")\n",
    "print(round(clf.score(X_test.drop(columns = ['words']), y_test),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465 1064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>wrong_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transcriptional</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tyrosine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>associated</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBP</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heavy</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>box</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word wrong_label\n",
       "0               2C           B\n",
       "1            beta3           B\n",
       "2                )           O\n",
       "3  transcriptional           O\n",
       "4         tyrosine           O\n",
       "5       associated           O\n",
       "6                P           B\n",
       "7              EBP           B\n",
       "8            heavy           O\n",
       "9              box           O"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample misclassifications are generated here\n",
    "\n",
    "res = clf.predict(X_test.drop(columns = ['words']))\n",
    "Counter(y_test['labels'])\n",
    "\n",
    "i_res  = []\n",
    "i_labels = []\n",
    "\n",
    "for i, ele in enumerate(y_test['labels']):\n",
    "    if ele == 'I':\n",
    "       i_res.append(res[i])\n",
    "\n",
    "\n",
    "misclass = []\n",
    "misclassified_class = []\n",
    "\n",
    "for i, ele in enumerate(y_test['labels']):\n",
    "    if ele == \"I\" and res[i] != 'I':\n",
    "        misclass.append(X_test['words'].tolist()[i])\n",
    "        misclassified_class.append(res[i])\n",
    "    \n",
    "c = 0\n",
    "\n",
    "for ele in i_res:\n",
    "    if ele == 'I':\n",
    "        c += 1\n",
    "\n",
    "        \n",
    "print(len(i_res), c)\n",
    "\n",
    "mis_df = pd.DataFrame()\n",
    "mis_df['word'] = misclass \n",
    "mis_df['wrong_label'] = misclassified_class\n",
    "mis_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_bc9d7_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >labels</th>        <th class=\"col_heading level0 col1\" >precision</th>        <th class=\"col_heading level0 col2\" >recall</th>        <th class=\"col_heading level0 col3\" >fscore</th>        <th class=\"col_heading level0 col4\" >support</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bc9d7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bc9d7_row0_col0\" class=\"data row0 col0\" >B</td>\n",
       "                        <td id=\"T_bc9d7_row0_col1\" class=\"data row0 col1\" >35.71%</td>\n",
       "                        <td id=\"T_bc9d7_row0_col2\" class=\"data row0 col2\" >55.78%</td>\n",
       "                        <td id=\"T_bc9d7_row0_col3\" class=\"data row0 col3\" >0.44</td>\n",
       "                        <td id=\"T_bc9d7_row0_col4\" class=\"data row0 col4\" >1660</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc9d7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bc9d7_row1_col0\" class=\"data row1 col0\" >I</td>\n",
       "                        <td id=\"T_bc9d7_row1_col1\" class=\"data row1 col1\" >35.82%</td>\n",
       "                        <td id=\"T_bc9d7_row1_col2\" class=\"data row1 col2\" >43.16%</td>\n",
       "                        <td id=\"T_bc9d7_row1_col3\" class=\"data row1 col3\" >0.39</td>\n",
       "                        <td id=\"T_bc9d7_row1_col4\" class=\"data row1 col4\" >2465</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bc9d7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bc9d7_row2_col0\" class=\"data row2 col0\" >O</td>\n",
       "                        <td id=\"T_bc9d7_row2_col1\" class=\"data row2 col1\" >94.67%</td>\n",
       "                        <td id=\"T_bc9d7_row2_col2\" class=\"data row2 col2\" >90.73%</td>\n",
       "                        <td id=\"T_bc9d7_row2_col3\" class=\"data row2 col3\" >0.93</td>\n",
       "                        <td id=\"T_bc9d7_row2_col4\" class=\"data row2 col4\" >34491</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29724865040>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of individual labels\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(y_test, res)\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores['labels'] = ['B', 'I', 'O']\n",
    "scores['precision'] = precision\n",
    "scores['recall'] = recall \n",
    "scores['fscore'] = fscore \n",
    "scores['support'] = support\n",
    "\n",
    "scores.style.format({\n",
    "    'precision': '{:,.2%}'.format,\n",
    "    'recall': '{:,.2%}'.format,\n",
    "    'fscore': '{:,.2f}'.format,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13795it [01:32, 148.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "      <td>[Comparison, with, alkaline, phosphatases, and...</td>\n",
       "      <td>[O, O, B, I, O, B, I, I, O]</td>\n",
       "      <td>[O, O, O, I, O, O, I, I, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[Pharmacologic, aspects, of, neonatal, hyperbi...</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[When, CSF, [, HCO3, -], is, shown, as, a, fun...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, B, O, B, I, O, O, O, O, O, O, B, B, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Flurazepam, thus, appears, to, be, an, effect...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[Beta, blocking, agents, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Expression, of, SREBP, -, 1a, stimulated, StA...</td>\n",
       "      <td>[O, O, B, I, I, O, B, I, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, B, I, B, O, O, I, O, O, O, O, O, B, I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Because, the, high, -, density, lipoprotein, ...</td>\n",
       "      <td>[O, O, B, I, I, I, I, O, B, I, I, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, I, O, I, I, O, B, I, B, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[IFN, -, stimulated, gene, factor, -, 3, and, ...</td>\n",
       "      <td>[B, I, I, I, I, I, I, O, B, I, O, O, O, O, B, ...</td>\n",
       "      <td>[B, I, O, I, I, I, I, O, B, O, O, O, O, O, B, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[We, have, therefore, studied, the, molecular,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, O, O, B, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, B, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13794</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[The, epitope, -, protected, lysine, (, K, ), ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B, I, I, ...</td>\n",
       "      <td>[O, O, I, O, O, O, B, O, O, O, O, O, O, I, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13795 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   index  \\\n",
       "0                            [1, 2, 3, 4, 5, 6, 7, 8, 9]   \n",
       "1                                     [1, 2, 3, 4, 5, 6]   \n",
       "2      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "4                                           [1, 2, 3, 4]   \n",
       "...                                                  ...   \n",
       "13790  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13791  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13792  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13793  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "13794  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                         tokenized_sents  \\\n",
       "0      [Comparison, with, alkaline, phosphatases, and...   \n",
       "1      [Pharmacologic, aspects, of, neonatal, hyperbi...   \n",
       "2      [When, CSF, [, HCO3, -], is, shown, as, a, fun...   \n",
       "3      [Flurazepam, thus, appears, to, be, an, effect...   \n",
       "4                            [Beta, blocking, agents, .]   \n",
       "...                                                  ...   \n",
       "13790  [Expression, of, SREBP, -, 1a, stimulated, StA...   \n",
       "13791  [Because, the, high, -, density, lipoprotein, ...   \n",
       "13792  [IFN, -, stimulated, gene, factor, -, 3, and, ...   \n",
       "13793  [We, have, therefore, studied, the, molecular,...   \n",
       "13794  [The, epitope, -, protected, lysine, (, K, ), ...   \n",
       "\n",
       "                                                   label  \\\n",
       "0                            [O, O, B, I, O, B, I, I, O]   \n",
       "1                                     [O, O, O, O, O, O]   \n",
       "2      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4                                           [O, O, O, O]   \n",
       "...                                                  ...   \n",
       "13790  [O, O, B, I, I, O, B, I, O, O, O, O, O, O, O, ...   \n",
       "13791  [O, O, B, I, I, I, I, O, B, I, I, O, O, O, O, ...   \n",
       "13792  [B, I, I, I, I, I, I, O, B, I, O, O, O, O, B, ...   \n",
       "13793  [O, O, O, O, O, O, O, O, B, I, I, O, O, B, O, ...   \n",
       "13794  [O, O, O, O, O, O, O, O, O, O, O, O, B, I, I, ...   \n",
       "\n",
       "                                           predicted_seq  \n",
       "0                            [O, O, O, I, O, O, I, I, O]  \n",
       "1                                     [O, O, O, O, O, O]  \n",
       "2      [O, B, O, B, I, O, O, O, O, O, O, B, B, O, O, ...  \n",
       "3      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4                                           [O, O, O, O]  \n",
       "...                                                  ...  \n",
       "13790  [O, O, B, I, B, O, O, I, O, O, O, O, O, B, I, ...  \n",
       "13791  [O, O, O, I, O, I, I, O, B, I, B, O, O, O, O, ...  \n",
       "13792  [B, I, O, I, I, I, I, O, B, O, O, O, O, O, B, ...  \n",
       "13793  [O, O, O, O, O, O, O, O, B, I, B, O, O, O, O, ...  \n",
       "13794  [O, O, I, O, O, O, B, O, O, O, O, O, O, I, O, ...  \n",
       "\n",
       "[13795 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "df['predicted_seq'] = ''\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    temp_list = []\n",
    "    temp_df = create_feature_df(row['tokenized_sents'])\n",
    "    # print(temp_df)\n",
    "    row['predicted_seq'] = clf.predict(temp_df.loc[:, temp_df.columns != 'labels'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(filename, df, label_col):\n",
    "    sentences = df.tokenized_sents.tolist()\n",
    "    labels = df[label_col].tolist()\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        for k,ele in enumerate(sentences):\n",
    "            for i,val in enumerate(zip(ele, labels[k])):\n",
    "                # print(ele, labels[k])\n",
    "                f.write(\"\\t\".join([str(i+1),val[0],val[1]]) + \"\\n\")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file('goldstandardfile.txt', df, 'label')\n",
    "write_to_file('yoursystemoutput.txt', df, 'predicted_seq')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
